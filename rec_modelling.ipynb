{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input, Merge, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy.ma as ma\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_func(y_true, y_pred):\n",
    "    temp = np.dot(y_true, y_pred)\n",
    "    temp_true = y_true.nonzero_values()\n",
    "    temp_pred = temp.nonzero_values()\n",
    "    temp_pred = temp_pred / temp_true\n",
    "    loss = T.mean((temp_pred - temp_true)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open('data/X.pkl', 'rb'))\n",
    "y = pickle.load(open('data/y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data = pickle.load(open('data/user_matrix.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, user_train, user_test = train_test_split(X, y, user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334063, 843)\n",
      "(334063, 843)\n",
      "(334063, 25)\n",
      "(111355, 25)\n",
      "(111355, 843)\n",
      "(111355, 843)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(user_train.shape)\n",
    "print(user_test.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445418, 843)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_dim = user_data.shape[1]\n",
    "rating_dim = X.shape[1]\n",
    "user_encoding_dim = 10\n",
    "encoding_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "del user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # this is our input placeholder\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from numpy.random import seed\n",
    "branch1 = Sequential()\n",
    "branch1.add(Dense(user_encoding_dim, input_shape = (user_dim,), init = 'normal', activation = 'relu'))\n",
    "branch1.add(Dropout(0.2))\n",
    " \n",
    "branch2 = Sequential()\n",
    "branch2.add(Dense(encoding_dim, input_shape =(rating_dim,), init = 'normal', activation = 'relu'))\n",
    "branch1.add(BatchNormalization())\n",
    "branch2.add(Dropout(0.2))\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Merge([branch1, branch2], mode = 'concat'))\n",
    "model.add(Dense(rating_dim, init = 'normal', activation = 'sigmoid'))\n",
    "model.compile(loss = loss_func, optimizer = 'adadelta')\n",
    "seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 10)            260                                          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 10)            40                                           \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            54016                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 843)           63225       merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 117,541\n",
      "Trainable params: 117,521\n",
      "Non-trainable params: 20\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(test, model, X_1, X_2):\n",
    "    y_pred = np.zeros(test.shape[0])\n",
    "    for i, t in enumerate(test):\n",
    "        pred = model.predict([X_1[t[2]].reshape(1, -1), X_2[t[2]].reshape(1, -1)])\n",
    "        pred = pred[0][t[2]]\n",
    "        y_pred[i] = pred * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0215    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0214    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0213    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0212    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0212    \n",
      "111200/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.021719344524941578\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0211    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0211    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0209    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0209    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0209    \n",
      "111168/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.021505777437117277\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0208    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0208    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0208    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0207    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0207    \n",
      "110592/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.0213723722338736\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0205    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0204    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0205    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0204    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0203    \n",
      "110560/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.021172788392217645\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0202    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0201    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0201    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0201    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0200    \n",
      "111264/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.021022438401158375\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0200    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0199    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0198    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0197    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0196    \n",
      "110528/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.020886076566989917\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0196    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0196    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0194    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0195    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0194    \n",
      "110912/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.020646076142696937\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0193    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0193    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0192    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0192    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0191    \n",
      "111072/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.02046687348666435\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0191    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0191    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 20s - loss: 0.0191    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 20s - loss: 0.0190    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 20s - loss: 0.0188    \n",
      "110752/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.020358168866978305\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0189    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0188    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0187    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0187    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0186    \n",
      "111296/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.02028010473204196\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0187    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0186    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0185    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0185    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0185    \n",
      "110528/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.020026420595616223\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0183    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0183    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0184    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0182    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0182    \n",
      "111008/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019885265646664377\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0181    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0180    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0180    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0181    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0180    \n",
      "110560/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019853337246414127\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0178    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0179    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0178    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0180    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0177    \n",
      "111328/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.01978386828447876\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0178    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0178    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0178    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0178    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0177    \n",
      "111296/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019724226781053723\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0176    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0177    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0176    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0176    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0175    \n",
      "110464/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019713860368113983\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0176    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0175    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0175    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0174    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0173    \n",
      "111136/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019612293599096397\n",
      "Epoch 1/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0173    \n",
      "Epoch 2/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0174    \n",
      "Epoch 3/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0174    \n",
      "Epoch 4/5\n",
      "334063/334063 [==============================] - 18s - loss: 0.0173    \n",
      "Epoch 5/5\n",
      "334063/334063 [==============================] - 19s - loss: 0.0173    \n",
      "111328/111355 [============================>.] - ETA: 0s\n",
      "training error: 0.019618029476755505\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    history = model.fit([user_train, X_train], y_train, nb_epoch=5, batch_size = 100)\n",
    "    losses.extend(history.history['loss'])\n",
    "    test_score = model.evaluate([user_test, X_test], y_test)\n",
    "    test_scores.append(test_score)\n",
    "    print('\\ntraining error: {}'.format(test_score))\n",
    "    if test_score > test_scores[-2]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(losses, open('data/losses.pkl', 'wb'))\n",
    "pickle.dump(test_scores, open('data/test_mse.pkl', 'wb'))\n",
    "model.save('model.h5')\n",
    "model.save_weights('model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
